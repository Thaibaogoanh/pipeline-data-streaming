services:
  # Zookeeper: cần cho Kafka phiên bản hiện tại
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:  
      - "2181:2181"
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka Broker: sử dụng image cp-server của Confluent
  broker:
    image: confluentinc/cp-server:7.4.0
    container_name: broker
    hostname: broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"       # Dành cho kết nối từ client bên ngoài
      - "9101:9101"       # Cổng JMX để giám sát (nếu cần)
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      CONFLUENT_METRICS_REPORTER_BOOTSTRAP_SERVERS: broker:29092
      CONFLUENT_METRICS_REPORTER_TOPIC_REPLICAS: 1
      CONFLUENT_METRICS_ENABLE: 'false'
      CONFLUENT_SUPPORT_CUSTOMER_ID: 'anonymous'
    networks:
      - pipeline-net
    healthcheck:
      test: ["CMD", "bash", "-c", "nc -z localhost 9092"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Spark Master: điều phối công việc của Spark
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    command: bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "9090:8080"   # Giao diện web của Spark Master
      - "7077:7077"   # Port để các worker kết nối
    volumes:
      - ./data/spark:/opt/bitnami/spark/data
      - ./app:/opt/bitnami/spark/app
    environment:
      - HADOOP_HOME=/opt/hadoop
      - hadoop.home.dir=/opt/hadoop
    networks:
      - pipeline-net

  # Spark Worker: thực hiện xử lý dữ liệu từ Spark Master
  spark-worker:
    image: bitnami/spark:latest
    container_name: spark-worker
    command: bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=1g
      - SPARK_MASTER_URL=spark://spark-master:7077
      - HADOOP_HOME=/opt/hadoop
      - hadoop.home.dir=/opt/hadoop
    volumes:
      - ./data/spark:/opt/bitnami/spark/data
      - ./app:/opt/bitnami/spark/app
    networks:
      - pipeline-net

  # Python Producer: đọc file CSV và gửi dữ liệu vào Kafka
  # python-producer:
  #   build: ./producer
  #   container_name: python-producer
  #   depends_on:
  #     - broker
  #   environment:
  #     KAFKA_BOOTSTRAP_SERVERS: broker:9092
  #     # Sử dụng biến môi trường cho tên topic để dễ thay đổi
  #     TOPIC_NAME: test-topic
  #   volumes:
  #     - ./producer:/app
  #     - ./data:/app/data  # Đặt file CSV vào thư mục này, ví dụ: AIR2301.csv
  #   networks:
  #     - pipeline-net

networks:
  pipeline-net:
    driver: bridge
